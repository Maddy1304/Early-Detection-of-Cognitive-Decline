# Early Detection of Cognitive Decline Using Multi-Modal Federated Learning with Edgeâ€“Fog Collaboration

## ğŸ§  Project Overview

This project implements a privacy-preserving, multi-modal federated learning system for early detection of cognitive decline (Alzheimer's and Parkinson's diseases) using edge-fog-cloud collaboration. The system processes speech, gait, and facial expression data locally on edge devices while maintaining patient privacy through federated learning.

## ğŸ¯ Key Features

- **Multi-Modal Data Processing**: Integrates speech, gait, and facial expression analysis
- **Federated Learning**: Privacy-preserving distributed training without sharing raw data
- **Edge-Fog-Cloud Architecture**: Hierarchical computing for low latency and scalability
- **Real-World Datasets**: Uses DAIC-WOZ, mPower, and RAVDESS datasets
- **Simulation Environment**: Complete simulation of healthcare infrastructure

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Edge Devices  â”‚    â”‚   Edge Devices  â”‚    â”‚   Edge Devices  â”‚
â”‚  (Smartphones/  â”‚    â”‚  (Wearables/    â”‚    â”‚  (IoT Sensors/  â”‚
â”‚   Tablets)      â”‚    â”‚   Smartwatches) â”‚    â”‚   Cameras)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Fog Nodes            â”‚
                    â”‚   (Clinic Servers)        â”‚
                    â”‚  - Model Aggregation      â”‚
                    â”‚  - Local Processing       â”‚
                    â”‚  - Privacy Filtering      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      Cloud Server         â”‚
                    â”‚   (Global Model)          â”‚
                    â”‚  - Global Aggregation     â”‚
                    â”‚  - Model Distribution     â”‚
                    â”‚  - Analytics & Reports    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
cognitive-decline-detection/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ edge_config.yaml
â”‚   â”œâ”€â”€ fog_config.yaml
â”‚   â”œâ”€â”€ cloud_config.yaml
â”‚   â””â”€â”€ model_config.yaml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ audio_processor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gait_processor.py
â”‚   â”‚   â”‚   â””â”€â”€ facial_processor.py
â”‚   â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ daic_woz.py
â”‚   â”‚   â”‚   â”œâ”€â”€ mpower.py
â”‚   â”‚   â”‚   â””â”€â”€ ravdess.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ speech_model.py
â”‚   â”‚   â”œâ”€â”€ gait_model.py
â”‚   â”‚   â”œâ”€â”€ facial_model.py
â”‚   â”‚   â”œâ”€â”€ multimodal_fusion.py
â”‚   â”‚   â””â”€â”€ base_model.py
â”‚   â”œâ”€â”€ federated_learning/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”œâ”€â”€ server.py
â”‚   â”‚   â”œâ”€â”€ aggregation.py
â”‚   â”‚   â””â”€â”€ privacy.py
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ edge_device.py
â”‚   â”‚   â”œâ”€â”€ fog_node.py
â”‚   â”‚   â”œâ”€â”€ cloud_server.py
â”‚   â”‚   â””â”€â”€ network_simulator.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ visualization.py
â”‚   â”‚   â””â”€â”€ benchmarking.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ config_loader.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ baseline_experiments.py
â”‚   â”œâ”€â”€ federated_experiments.py
â”‚   â”œâ”€â”€ privacy_analysis.py
â”‚   â””â”€â”€ scalability_tests.py
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â”œâ”€â”€ model_development.ipynb
â”‚   â”œâ”€â”€ federated_learning_demo.ipynb
â”‚   â””â”€â”€ results_analysis.ipynb
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data_processing.py
â”‚   â”œâ”€â”€ test_models.py
â”‚   â”œâ”€â”€ test_federated_learning.py
â”‚   â””â”€â”€ test_infrastructure.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ api_reference.md
â”‚   â”œâ”€â”€ deployment_guide.md
â”‚   â”œâ”€â”€ privacy_analysis.md
â”‚   â””â”€â”€ performance_benchmarks.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_datasets.py
â”‚   â”œâ”€â”€ setup_environment.py
â”‚   â”œâ”€â”€ run_experiments.py
â”‚   â””â”€â”€ deploy_simulation.py
â””â”€â”€ results/
    â”œâ”€â”€ logs/
    â”œâ”€â”€ models/
    â”œâ”€â”€ plots/
    â””â”€â”€ reports/
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-capable GPU (recommended)
- 16GB+ RAM
- 50GB+ free disk space

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd cognitive-decline-detection
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download datasets**
```bash
python scripts/download_datasets.py
```

5. **Run simulation**
```bash
python scripts/run_experiments.py --experiment baseline
```

## ğŸ“Š Datasets

> **Note**: Datasets are not included in this repository due to their large size. Please download them separately using the instructions below.

### DAIC-WOZ (Depression and Anxiety in Context)
- **Purpose**: Speech and facial expression analysis
- **Size**: ~189 hours of audio-visual data
- **Features**: Audio, video, transcriptions, PHQ-8 scores
- **Download**: Use `python scripts/download_datasets.py --dataset daic_woz`


### RAVDESS (Ryerson Audio-Visual Database)
- **Purpose**: Emotional speech recognition
- **Size**: 7,356 files
- **Features**: Audio files with emotional labels
- **Download**: Use `python scripts/download_datasets.py --dataset ravdess`
- **Manual Setup**: 
  1. Download from: https://zenodo.org/record/1188976
  2. Extract to `data/ravdess/`
  3. Expected structure:
     ```
     data/ravdess/
     â”œâ”€â”€ Audio_Speech_Actors_01-24/
     â”œâ”€â”€ Video_Speech_Actors_01-24/
     â””â”€â”€ README.txt
     ```

## ğŸ”¬ Experiments

### Baseline Experiments
- Centralized training on each modality
- Performance comparison across datasets
- Model architecture optimization

### Federated Learning Experiments
- Privacy-preserving distributed training
- Communication efficiency analysis
- Convergence behavior study

### Privacy Analysis
- Differential privacy implementation
- Privacy-utility trade-off evaluation
- Attack resistance testing

### Scalability Tests
- Edge device simulation (10-1000 devices)
- Fog node performance analysis
- Network latency impact study

## ğŸ“ˆ Key Metrics

- **Accuracy**: Overall classification performance
- **Precision/Recall**: Per-class performance metrics
- **F1-Score**: Harmonic mean of precision and recall
- **Communication Overhead**: Data transfer efficiency
- **Latency**: End-to-end processing time
- **Privacy Budget**: Differential privacy cost

## ğŸ”’ Privacy Features

- **Federated Learning**: No raw data sharing
- **Differential Privacy**: Mathematical privacy guarantees
- **Secure Aggregation**: Cryptographic model update protection
- **Local Processing**: Edge device data processing

## ğŸ› ï¸ Development

### Running Tests
```bash
pytest tests/
```

### Code Quality
```bash
black src/
flake8 src/
mypy src/
```

### Documentation
```bash
sphinx-build docs/ docs/_build/
```

## ğŸ“š Research Background

This project addresses critical gaps in healthcare AI:

1. **Limited Multimodal Integration**: Most FL systems use single data types
2. **Cognitive Disorder Focus**: Early detection of Alzheimer's/Parkinson's
3. **Real-World Deployment**: Practical edge-fog-cloud implementation
4. **Privacy-Latency Balance**: Optimized trade-offs for healthcare

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“ Contact

For questions and collaboration, please contact [your-email@domain.com]

## ğŸ™ Acknowledgments

- DAIC-WOZ dataset contributors
- mPower study participants
- RAVDESS dataset creators
- Federated learning research community

---

**Note**: This is a research prototype for simulation purposes. Not intended for clinical use without proper validation and regulatory approval.
